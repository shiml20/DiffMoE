<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/doge.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- 加一个图片 -->
            <img src="static/images/logo.png" alt="Logo" width="80%" height="100%">
            <!-- End image -->
            <h1 class="title is-1 publication-title">DiffMoE: Dynamic Token Selection for Scalable Diffusion Transformers</h1>
            
            <!-- 把上面的author 列表换成下面这种 html 格式 -->
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://github.com/shiml20" target="_blank">Minglei Shi</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://github.com/yzy1996" target="_blank">Ziyang Yuan</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=fWxWEzsAAAAJ&hl=en" target="_blank">Haotian Yang</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://xinntao.github.io/" target="_blank">Xintao Wang</a><sup>2†</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com.hk/citations?user=MdizB60AAAAJ&hl=en" target="_blank">Mingwu Zheng</a><sup></sup>,</span>
              <span class="author-block">
                <a href="https://www.xtao.website/" target="_blank">Xin Tao</a><sup></sup>,</span>
              <span class="author-block">
                <a href="https://wl-zhao.github.io/" target="_blank">Wenliang Zhao</a><sup>1</sup>,</span>
                <a href="https://wl-zhao.github.io/" target="_blank">Wenzhao Zheng</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.imem.tsinghua.edu.cn/info/1330/2128.htm" target="_blank">Jie Zhou</a><sup>1</sup>,
                <a href="https://www.imem.tsinghua.edu.cn/info/1330/2128.htm" target="_blank">Jiwen Lu</a><sup>1†</sup>,
                <a href="https://openreview.net/profile?id=~Di_ZHANG3" target="_blank">Pengfei Wan</a><sup>2</sup>,</span>
                <a href="https://openreview.net/profile?id=~Di_ZHANG3" target="_blank">Di Zhang</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=PXO4ygEAAAAJ&hl=zh-CN" target="_blank">Kun Gai</a><sup>2</sup>
              </span>
            </div>


                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Tsinghua University <sup>2</sup>Kuaishou Technology</span>
                    <!-- <span class="author-block"><sup>1</sup>Tsinghua University <sup>2</sup>Tsinghua University <br>Conferance name and year</span> -->
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small><small> <sup>†</sup>Indicates Corresponding Author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/KwaiVGI/DiffMoE.git" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- 居中写一个小点的tldr -->
      <h2 class="subtitle has-text-centered"><strong>TL;DR:</strong>
        We propose DiffMoE to efficiently scaling the Diffusion Transformers.
      </h2>
      <!-- 居中写一个加粗的 tldr -->
      <!-- <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
        <!-- <source src="static/videos/banner_video.mp4" type="video/mp4"> -->
        <!-- <source src="static/videos/banner_video.mp4" type="video/mp4"> -->
      <!-- </video> -->
      <img src="static/images/teaser.png" alt="Logo" width="100%" height="100%">
      <p>
        Token Accessibility and Dynamic Computation. (a) Token accessibility levels from token isolation to crosssample interaction. Colors represent tokens in different samples, ti indicates noise levels. (b) Performance-accessibility analysis across architectures. (c) Computational dynamics during diffusion sampling, showing adaptive computation from noise to image. (d) Class-wise computation allocation from hard (technical diagrams) to easy (natural photos) tasks. Results from DiffMoE-L-E16-Flow (700K). 
      </p>
      <!-- <h2 class="subtitle has-text-centered"> -->
        <!-- Token Accessibility and Dynamic Computation. (a) Token accessibility levels from token isolation to crosssample interaction. Colors represent tokens in different samples, ti indicates noise levels. (b) Performance-accessibility analysis across architectures. (c) Computational dynamics during diffusion sampling, showing adaptive computation from noise to image. (d) Class-wise computation allocation from hard (technical diagrams) to easy (natural photos) tasks. Results from DiffMoE-L-E16-Flow (700K).  -->
      <!-- </h2> -->
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <!-- 把下面一段文字有 latex 格式的地方加粗 -->
              <p>
              Diffusion models have demonstrated remarkable success in various image generation tasks, 
              but their performance is often limited by the uniform processing of inputs across varying conditions and noise levels. 
              To address this limitation, we propose a novel approach that leverages the inherent heterogeneity of the diffusion process. 
              Our method, <strong>DiffMoE</strong>, introduces a <strong>batch-level global token pool</strong> that enables experts to access global token distributions during training, 
              promoting specialized expert behavior. To unleash the full potential of the diffusion process, 
              DiffMoE incorporates a <strong>capacity predictor</strong> that dynamically allocates computational resources based on noise levels and sample complexity. 
              Through comprehensive evaluation,  DiffMoE  achieves state-of-the-art performance among diffusion models on ImageNet benchmark, 
              substantially outperforming both dense architectures with 3x activated parameters and existing MoE approaches while maintaining 1x activated parameters. 
              The effectiveness of our approach extends beyond class-conditional generation to more challenging tasks such as text-to-image generation, demonstrating its broad applicability across different diffusion model applications.  
            </p>
          </div>
        </div>
      </div>
  </div>

</section>
<!-- End paper abstract -->


<!-- Paper Method -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <!-- 把下面一段文字有 latex 格式的地方加粗 -->
            <p>
              DiffMoE Architecture Overview. DiffMoE flattens tokens into a batch-level global token pool, where each expert maintains a fixed training capacity. 
              During inference, a dynamic capacity predictor adaptively routes tokens across different sampling steps and conditions. 
              Different colors denote tokens from distinct samples, while ti represents corresponding noise levels.
          </p>
          <div class="columns is-centered has-text-justified">
            <td colspan="3">
              <img src="static/images/Method.png" alt="method" width="100%" />
            </td>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Paper Method -->


<!-- Paper Method -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experiments</h2>
        <div class="content has-text-justified">
          <!-- 把下面一段文字有 latex 格式的地方加粗 -->
            <p>
              <strong>ImageNet Generation.</strong> After 7000K steps, DiffMoE-L-E8 achieves state-of-the-art FID50K 
              scores of DDPM/Flow (2.30/2.13)  with cfg=1.5, surpassing Dense-DiT-XL (2.32/2.19) as shown below. All evaluations follow DiT's protocol.  
            </p>
          <div class="columns is-centered has-text-justified">
            <td colspan="3">
              <img src="static/images/SOTA.png" alt="method" width="100%" />
            </td>
            <p>
              <strong>Scaling Parameter Behavior.</strong> After 3000K steps, 
              To explore the upper limits of DiffMoE and quantify its performance efficiency, we scaled the model to larger sizes and trained them for 3000K steps. DiffMoE-L-E16-Flow achieves the best performance among the evaluated models. 
              Notably, DiffMoE-L-E16 surpasses the performance of Dense-DiT-XXXL-Flow, which uses 3x the parameters, while operating with only 1x the parameters. This highlights the exceptional parameter efficiency and scalability of DiffMoE.
            </p>
          <div class="columns is-centered has-text-justified">
            <td colspan="3">
              <img src="static/images/SOTA.png" alt="method" width="100%" />
            </td>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Paper Method -->



<!-- Paper Method -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Visualization</h2>
        <div class="content has-text-justified">
          <!-- 把下面一段文字有 latex 格式的地方加粗 -->
            <p>
              <!-- DiffMoE Architecture Overview. DiffMoE flattens tokens into a batch-level global token pool, where each expert maintains a fixed training capacity. During inference, a dynamic capacity predictor adaptively routes tokens across different sampling steps and conditions. Different colors denote tokens from distinct samples, while ti represents corresponding noise levels. -->
          </p>
          <div class="columns is-centered has-text-justified">
            <td colspan="3">
              <img src="static/images/viz-1.png" alt="method" width="100%" />
            </td>
            <td colspan="3">
              <img src="static/images/viz-2.png" alt="method" width="100%" />
            </td>
            <td colspan="3">
              <img src="static/images/viz-3.png" alt="method" width="100%" />
            </td>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Paper Method -->


<!-- Paper Method -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Analysis</h2>
        <div class="content has-text-justified">
          <!-- 把下面一段文字有 latex 格式的地方加粗 -->
            <p>
              <!-- DiffMoE Architecture Overview. DiffMoE flattens tokens into a batch-level global token pool, where each expert maintains a fixed training capacity. During inference, a dynamic capacity predictor adaptively routes tokens across different sampling steps and conditions. Different colors denote tokens from distinct samples, while ti represents corresponding noise levels. -->
          </p>
          <div class="columns is-centered has-text-justified">
            <td colspan="3">
              <img src="static/images/ana-1.png" alt="method" width="100%" />
            </td>
            <td colspan="3">
              <img src="static/images/ana-2.png" alt="method" width="100%" />
            </td>
            </td>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Paper Method -->



<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{shi2025diffmoe,
        title={DiffMoE: Dynamic Token Selection for Scalable Diffusion Transformers},
        author={Shi, Minglei and Yuan, Ziyang and Yang, Haotian and Wang, Xintao and Zheng, Mingwu and Tao,  Xin and Zhao, Wenliang and Zheng, Wenzhao and Zhou, Jie and Lu, Jiwen and Wan, Pengfei and ZHANG, Di and Gai, Kun },
        journal={arXiv preprint arXiv:xxxx},
        year={2025}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
